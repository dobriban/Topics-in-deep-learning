# STAT 991: Topics in deep learning (UPenn)

STAT 991: Topics in Deep Learning is a seminar class at UPenn started in 2018. It surveys advanced topics in deep learning based on student presentations. 

# Fall 2019

* [Syllabus](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Syllabus/stat-991-fall-2019-syllabus.pdf). 

* [Lecture notes](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Lecture%20Notes/stat_991.pdf). (~170 pages, file size ~30 MB, mostly covering notes from previous semesters.)

## Lectures

Lectures 1 and 2: Introduction and uncertainty quantification ([jackknife+](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202019/Slides/BarberSlides-whoa-psi-2019.pdf), and [Pearce at al, 2018](http://proceedings.mlr.press/v80/pearce18a.html)), presented by Edgar Dobriban. 

Lecture 3: [NTK](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202019/Slides/stat991_ntk_sep12.pdf) by Jiayao Zhang. [Blog post](http://www.offconvex.org/2019/10/03/NTK/) on the off-convex blog.

Lecture 4: [Adversarial robustness](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202019/Slides/adversarial_robustness_yinjun_Lec_3_(9.19).pdf) by Yinjun Wu.

Lecture 5: [ELMo and BERT](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202019/Slides/contextual-word-embeddings.pdf) by Dan Deutsch.

Lecture 6: [TCAV](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202019/Slides/stat991_auerbach_prez.pptx) by Ben Auerbach (adapted from Been Kim's slides).

Lecture 7: [Spherical CNN](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202019/Slides/STAT991_spherical_cnn.pdf) by Arjun Guru and Claudia Zhu.

Lecture 8: [DNNs and approximation](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202019/Slides/DNN_presentation_yebiao.pdf) by Yebiao Jin.

Lecture 9: [Deep Learning and PDE](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202019/Slides/STAT%20991%20DL%20Chenyang%20(3).pdf) by Chenyang Fang.

   [Bias and Fairness](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202019/Slides/Stat991_Chetan.pdf) by Chetan Parthiban.

Lecture 10: [Generalization](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202019/Slides/ML_Generalization_Lynch_20191107.pptx) by Bradford Lynch.

 [Double Descent](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202019/Slides/STAT991_double_descent.pdf) by Junhui Cai, adapted from slides by Misha Belkin and Ryan Tibshirani.

Lecture 11: [Deep Learning in Practice](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202019/Slides/Dewang_Sultania_Deep_Learning_in_Practice.pdf) by Dewang Sultania, adaping some slides from CIS 700. [Colab notebook](https://colab.research.google.com/drive/1FPwvn0Fm0kjUR6Dx4HGrZHQUfPvaWPoU)

Lecture 12: [Hindsight Experience Replay](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202019/Slides/STAT991%20-%20Achin%20Jain.pptx) by Achin Jain.

Lecture 13: [Deep Learning and Chemistry](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202019/Slides/Deep%20Learning%20and%20Chemical%20Design.pdf) by Chris Koch.

[Text summarization](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202019/Slides/991Presentation.pptx) by Jamaal Hay.


Lecture 14: [Deep Learning and Langevin Dynamics](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202019/Slides/Langevin_and_DNN.pdf), and [lecture notes](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202019/Slides/Langevin_notes.pdf)  by Kan Chen.

[Deep Learning in Asset Pricing](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202019/Slides/Zhu%20slides.pdf) by Wu Zhu.



### Topics 

* Potential topics: Uncertainty quantification, Adversarial Examples, Symmetry, Theory and Empirics, Interpretation, Fairness,  ...

* Potential papers:

### Uncertainty quantification

  [Predictive inference with the jackknife+](https://arxiv.org/abs/1905.02928). [Slides](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202019/Slides/BarberSlides-whoa-psi-2019.pdf). 

  [High-Quality Prediction Intervals for Deep Learning: A Distribution-Free, Ensembled Approach](http://proceedings.mlr.press/v80/pearce18a.html)

### Adversarial Examples

[Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples](https://arxiv.org/abs/1802.00420)

[Certified Adversarial Robustness via Randomized Smoothing](https://arxiv.org/abs/1902.02918)

[On Evaluating Adversarial Robustness](https://arxiv.org/abs/1902.06705)

[VC Classes are Adversarially Robustly Learnable, but Only Improperly](https://arxiv.org/abs/1902.04217)

[Adversarial Examples Are Not Bugs, They Are Features](https://arxiv.org/abs/1905.02175)

See section 6.1 of [my lecture notes](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Lecture%20Notes/stat_991.pdf) for a collection of materials.

### Symmetry

[Spherical CNNs](https://arxiv.org/abs/1801.10130)

[Learning SO(3) Equivariant Representations with Spherical CNNs](http://openaccess.thecvf.com/content_ECCV_2018/html/Carlos_Esteves_Learning_SO3_Equivariant_ECCV_2018_paper.html)

[Invariance reduces Variance: Understanding Data Augmentation in Deep Learning and Beyond](https://arxiv.org/abs/1907.10905)


### Theory and empirical wonders

[Understanding deep learning requires rethinking generalization](https://arxiv.org/abs/1611.03530)

[Spectrally-normalized margin bounds for neural networks](http://papers.nips.cc/paper/7204-spectrally-normalized-margin-bounds-for-neural-networks)

[Neural Tangent Kernel: Convergence and Generalization in Neural Networks](https://arxiv.org/abs/1806.07572). [GNTK](https://arxiv.org/abs/1905.13192). 

[Gradient Descent Provably Optimizes Over-parameterized Neural Networks](https://arxiv.org/abs/1810.02054)

[Mean-field theory of two-layers neural networks](https://arxiv.org/abs/1804.06561). [Youtube talk](https://www.youtube.com/watch?v=eMFqg-B0oPE)

### Interpretation

[Interpretability beyond feature attribution: Quantitative testing with concept activation vectors (tcav)](https://arxiv.org/abs/1711.11279)

[Sanity checks for saliency maps](http://papers.nips.cc/paper/8160-sanity-checks-for-saliency-maps)

### Scalability and Federated Learning

[Communication-Efficient Learning of Deep Networks from Decentralized Data](https://arxiv.org/abs/1602.05629)

[Federated Learning: Challenges, Methods, and Future Directions](https://arxiv.org/abs/1908.07873)

### Fairness

[TBA]


### Applications

Climate, energy, healthcare...

## Other resources

[Course on Coursera.](https://www.coursera.org/specializations/deep-learning) A good way to learn the basics.

Stanford classes: [CS231N (Computer vision)](http://cs231n.stanford.edu/). [CS224N (NLP)](http://web.stanford.edu/class/cs224n/). [Cheat sheet](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-deep-learning).

Conferences: [NeurIPS](https://nips.cc/), [ICML](https://icml.cc/), [ICLR](https://iclr.cc/)

Convenient ways to run code online: https://colab.research.google.com/notebooks/welcome.ipynb, https://www.kaggle.com/kernels

Keras is a user-friendly language for DL. Interfaces to R, see this [book](https://livebook.manning.com/book/deep-learning-with-r/about-this-book/)

[Foundations of Deep Learning program at the Simons Institute for the Theory of Computing](https://simons.berkeley.edu/programs/dl2019). workshops: [1](https://simons.berkeley.edu/workshops/schedule/10624), [2](https://simons.berkeley.edu/workshops/schedule/10627), [3](https://simons.berkeley.edu/workshops/schedule/10629). [Reading groups and papers](http://simons.squidhive.net/doku.php)

[IAS Special Year on Optimization, Statistics, and Theoretical Machine Learning](http://www.math.ias.edu/sp/Optimization_Statistics_and_Theoretical_Machine_Learning)

# Materials from previous editions

# Lecture notes

The materials draw inspiration from many sources, including David Donoho's course Stat 385 at Stanford, Andrew Ng's Deep Learning course on deeplearning.ai, CS231n at Stanford, David Silver's RL course, Tony Cai's reading group at Wharton. They may contain factual and typographical errors. Thanks to several people who have provided parts of the notes, including Zongyu Dai, Georgios Kissas, Jane Lee, Barry Plunkett, Matteo Sordello, Yibo Yang, Bo Zhang, Yi Zhang, Carolina Zheng. The images included are subject to copyright by their rightful owners, and are included here for educational purposes.

* [Lecture notes](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Lecture%20Notes/stat_991.pdf). (~170 pages, file size ~30 MB.)

Compared to other sources, these lecture notes are aimed at people with a basic knowledge of probability, statistics, and machine learning. They start with basic concepts from deep learning, and aim to cover selected important topics up to the cutting edge of research.

The entire latex source is included, encouraging reuse (subject to appropriate licenses).


# Spring 2019

Topics: sequential decision-making (from bandits to deep reinforcement learning),  distributed learning, AutoML, Visual Question Answering.

* [Syllabus](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Syllabus/stat-991-spring-2019-syllabus.pdf). 

## Presentations

* [Lecture 1: Bandits](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Spring%202019/STAT-991-Spring-2019-Lec-1-Bandits.pdf). Presented by Edgar Dobriban.

* [Lecture 2: Contextual Bandits](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Spring%202019/STAT-991-Spring-2019-Lec-2b-Bo-Contextual%20Bandits.pdf). Presented by Bo Zhang.

* [Lecture 2b: Contextual Bandits for Mobile Health](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Spring%202019/STAT-991-Spring-2019-Lec%203a-Halley-Contextual-Bandits-for-Mobile-Health.pdf). Presented by Halley Young.

* Lectures 4-9: Reinforcement learning following David Silver's course.

* [Lecture 11: Hierarchical Reinforcement learning](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Spring%202019/STAT-991-Spring-2019-Lec-11b-Barry-Plunkett-Hierarchical-RL.pdf). Presented by Barry Plunkett.

* [Lecture 12: AutoML](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Spring%202019/STAT-991-Spring-2019-Lec-12-Yi-AutoML.pdf). Presented by Yi Zhang.

* [Lecture 13: Visual Question Answering](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Spring%202019/STAT-991-Spring-2019-Lec-13-Reno-Kriz-Visual-Question-Answering.pptx). Presented by Reno Kriz.

* [Lecture 13b: Visual Question Answering: Part 2](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Spring%202019/STAT-991-Spring-2019-Lec-13b-Soham-VQA_Attention_RL.pdf). Presented by Soham Parikh.

# Fall 2018

Topics: basics (deep feedforward networks, training, CNNs, RNNs). Generative Adversarial Networks, Learning Theory, Sequence Learning, Neuroscience, etc.


* [Syllabus](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Syllabus/stat-991-fall-2018-syllabus.pdf). 

## Presentations

* Lectures 1-3: Lectures based on Edgar Dobriban's notes.

* [Lecture 4: Generative Adversarial Networks](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202018/991-Lec-4-GAN_Zilu.pdf). Presented by Zilu Zhou.

* [Lecture 5: Theory for Generative Adversarial Networks](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202018/991-Lec-5-GAN_Theory_Elzayn.pdf). Presented by Hadi Elzayn.

* [Lecture 6: Learning Theory for Neural Networks](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202018/991-Lec-6-Learning_Theory_Jacob.pdf). Presented by Jacob Seidman.

* [Lecture 7: Gradient Based Optimization](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202018/991-Lec-7-Gradient%20Descent_Matteo.pdf). Presented by Matteo Sordello.

* [Lecture 8: Sequence Learning](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202018/991-Lec8-Sequence%20Learning_Carolina.pdf). Presented by Carolina Zheng.

* [Lecture 9: Robotics](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202018/991-Lec-9-Robotics_Ty.pptx). Presented by Ty Nguyen.

* [Lecture 10: Autoencoders, Physics-Informed Neural Networks](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202018/991-Lec-10-Autoencoders+Differential-Equations_Yibo_Georgios.pdf). Presented by Yibo Yang and Georgios Kissas.

* [Lecture 11: Neuroscience Inspired Deep Learning](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202018/991-Lec-11-Neuroscience-inspired-deep-learning_-_Huy.pdf). Presented by Huy Le.

* [Lecture 12: Approximation and Estimation for Deep Learning Networks](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202018/991-Lec-12-Approximation-and-Estimation-for-Deep-Learning-Networks_-_Jason_Klusowski.pdf). Guest lecture by Jason Klusowski.

* [Lecture 13: Deep Learning in Marketing Research](https://github.com/dobriban/Topics-in-deep-learning/blob/master/Stat%20991%20presentations/Fall%202018/991-Lec-13-Deep-Learning-in-Marketing-Research-Mingyung-Kim.pdf). Presented by Mingyung Kim.

# Materials for future editions

Relatively more recent developments or additions.

## Papers 

### Applications and Methods

* [Significance tests in deep learning](https://github.com/Kaleidophon/deep-significance)

* [Few-Shot Adversarial Learning of Realistic Neural Talking Head Models](http://openaccess.thecvf.com/content_ICCV_2019/html/Zakharov_Few-Shot_Adversarial_Learning_of_Realistic_Neural_Talking_Head_Models_ICCV_2019_paper.html)

* [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165), from OpenAI, introducing GPT-3. See [Youtube video](https://www.youtube.com/watch?v=SY5PvZrJhLE) explanation by Yannic Kilcher. Argument: is it more than just elaborate pattern-matching (a lookup table)?

* [A Simple Framework for Contrastive Learning of Visual Representations](https://arxiv.org/abs/2002.05709), introducing SimCLR, a prominent method for self-supervised learning

* [A Survey on Bias and Fairness in Machine Learning](https://arxiv.org/abs/1908.09635)

* [Concrete Problems in AI Safety](https://arxiv.org/abs/1606.06565)


### Theory

* [Machine Learning from a Continuous Viewpoint](https://arxiv.org/abs/1912.12777); [Towards a Mathematical Understanding of Neural Network-Based Machine Learning: what we know and what we don't](https://arxiv.org/abs/2009.10713)

* [Theoretical issues in deep networks](https://www.pnas.org/content/early/2020/06/08/1907369117)

* [Polylogarithmic width suffices for gradient descent to achieve arbitrarily small test error with shallow ReLU networks](https://arxiv.org/abs/1909.12292)

* [The large learning rate phase of deep learning: the catapult mechanism](https://arxiv.org/abs/2003.02218)

* [Symmetry & critical points for a model shallow neural network](https://arxiv.org/abs/2003.10576), also: [Analytic Characterization of the Hessian in Shallow ReLU Models: A Tale of Symmetry
](https://arxiv.org/abs/2008.01805)

* [Prevalence of Neural Collapse during the terminal phase of deep learning training](https://arxiv.org/abs/2008.08186)

* [Traces of Class/Cross-Class Structure Pervade Deep Learning Spectra](https://arxiv.org/abs/2008.11865)

* [Generalization bound of globally optimal non-convex neural network training: Transportation map estimation by infinite dimensional Langevin dynamics](https://arxiv.org/abs/2007.05824)



## Books and other educational materials

* [Dive into Deep Learning: An interactive deep learning book with code, math, and discussions, based on the NumPy interface](http://d2l.ai/), see also [Reddit post](https://www.reddit.com/r/MachineLearning/comments/fvq3n6/p_dive_into_deep_learning_an_interactive_deep/)

* [DeepMind x UCL | Deep Learning Lectures 2020](https://www.youtube.com/watch?v=7R52wiUgxZI&list=PLqYmG7hTraZCDxZ44o4p3N5Anz3lLRVZF&index=1)

* [Deep Learning with PyTorch Course by Alfredo Canziani at NYU](https://atcold.github.io/pytorch-Deep-Learning/), co-taught with Yann LeCun. Has slides, videos, code etc.

* [EPFL EE-559 – DEEP LEARNING](https://fleuret.org/ee559/) by Francois Fleuret

* [Deep Learning Courses by Marc Lelarge](https://mlelarge.github.io/dataflowr-web), taught at Ecole Polytechnique, ENS, etc

* [AtHomeWithAI](https://storage.googleapis.com/deepmind-media/research/New_AtHomeWithAI%20resources.pdf) Curated Resource List by DeepMind

* [Machine Learning Summer School 2020, Tuebingen](http://mlss.tuebingen.mpg.de/2020/schedule.html), see also materials from previous years at [mlss.cc](http://mlss.cc/)

* [Eastern European Machine Learning Summer School (EEML), 2020](https://www.eeml.eu/program), recorded lectures. see e.g., the lecture by Misha Belkin on the theory of deep learning.

## Implementation and reproducibility

* [AI Research, Replicability and Incentives](https://dennybritz.com/blog/ai-replication-incentives), by Denny Britz

## Online seminar series

* [IAS ML](https://twitter.com/iasmlseminars?lang=en)

* [DEEP LEARNING: CLASSICS AND TRENDS](http://rosanneliu.com/dlct/)

* [One World ML](https://www.oneworldml.org/)

* [1W-MINDS](https://sites.google.com/view/minds-seminar/home)

* [Math for Arbitrary Data Sources (NOMADS)](http://www.nonlocal-methods.eu/oneworld/)






